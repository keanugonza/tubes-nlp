{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a7795dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Converting to token classification format...\n",
      "Found 1094 reviews with NER annotations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to train_ner.csv\n",
      "Total samples: 1094\n",
      "\n",
      "=== Dataset Statistics ===\n",
      "Total tokens: 251286\n",
      "\n",
      "Tag distribution:\n",
      "  O: 240055 (95.53%)\n",
      "  I-MOVIE: 2396 (0.95%)\n",
      "  B-ACTOR: 2179 (0.87%)\n",
      "  I-ACTOR: 1962 (0.78%)\n",
      "  B-MOVIE: 1629 (0.65%)\n",
      "  B-CHARACTER: 1250 (0.50%)\n",
      "  I-CHARACTER: 627 (0.25%)\n",
      "  B-DIRECTOR: 479 (0.19%)\n",
      "  I-DIRECTOR: 390 (0.16%)\n",
      "  B-GENRE: 266 (0.11%)\n",
      "  I-GENRE: 53 (0.02%)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(text_path, label_path):\n",
    "    \"\"\"Load text and label JSON files\"\"\"\n",
    "    with open(text_path, 'r', encoding='utf-8') as f:\n",
    "        text_data = json.load(f)\n",
    "\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        label_data = json.load(f)\n",
    "\n",
    "    return text_data, label_data\n",
    "\n",
    "def convert_to_token_classification(text_data, label_data):\n",
    "    \"\"\"\n",
    "    Convert the NER data to token classification format.\n",
    "    Returns a list of dictionaries with 'id', 'text', and 'entities' fields.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    # Create a mapping from id to text\n",
    "    id_to_text = {review['id']: review['text'] for review in text_data['reviews']}\n",
    "\n",
    "    # Process each result\n",
    "    for result in label_data['results']:\n",
    "        review_id = result['id']\n",
    "\n",
    "        # Get the corresponding text\n",
    "        if review_id not in id_to_text:\n",
    "            continue\n",
    "\n",
    "        text = id_to_text[review_id]\n",
    "\n",
    "        # Get NER entities\n",
    "        ner_data = result.get('ner', {})\n",
    "        entities = ner_data.get('entities', [])\n",
    "\n",
    "        # Skip reviews with no entities\n",
    "        if not entities:\n",
    "            continue\n",
    "\n",
    "        # Convert entities to the format with character positions\n",
    "        # Filter out SERIES entities\n",
    "        formatted_entities = []\n",
    "        for entity in entities:\n",
    "            entity_text = entity['text']\n",
    "            entity_label = entity['label']\n",
    "\n",
    "            # Skip SERIES entities\n",
    "            if entity_label == 'SERIES':\n",
    "                continue\n",
    "\n",
    "            # Find all occurrences of the entity in the text\n",
    "            start_idx = 0\n",
    "            while True:\n",
    "                pos = text.find(entity_text, start_idx)\n",
    "                if pos == -1:\n",
    "                    break\n",
    "\n",
    "                formatted_entities.append({\n",
    "                    'text': entity_text,\n",
    "                    'label': entity_label,\n",
    "                    'start': pos,\n",
    "                    'end': pos + len(entity_text)\n",
    "                })\n",
    "\n",
    "                # For now, just take the first occurrence\n",
    "                break\n",
    "\n",
    "        if formatted_entities:\n",
    "            processed_data.append({\n",
    "                'id': review_id,\n",
    "                'text': text,\n",
    "                'entities': formatted_entities\n",
    "            })\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "def create_bio_tags(text, entities):\n",
    "    \"\"\"\n",
    "    Create BIO tags for the text based on entities.\n",
    "    Returns tokens and their corresponding BIO tags.\n",
    "    \"\"\"\n",
    "    # Simple whitespace tokenization\n",
    "    tokens = text.split()\n",
    "    labels = ['O'] * len(tokens)\n",
    "\n",
    "    # Track character position for each token\n",
    "    char_to_token = {}\n",
    "    current_pos = 0\n",
    "    for token_idx, token in enumerate(tokens):\n",
    "        token_start = text.find(token, current_pos)\n",
    "        token_end = token_start + len(token)\n",
    "        for char_idx in range(token_start, token_end):\n",
    "            char_to_token[char_idx] = token_idx\n",
    "        current_pos = token_end\n",
    "\n",
    "    # Assign BIO tags\n",
    "    for entity in entities:\n",
    "        entity_start = entity['start']\n",
    "        entity_end = entity['end']\n",
    "        entity_label = entity['label']\n",
    "\n",
    "        # Find tokens that overlap with this entity\n",
    "        entity_tokens = set()\n",
    "        for char_idx in range(entity_start, entity_end):\n",
    "            if char_idx in char_to_token:\n",
    "                entity_tokens.add(char_to_token[char_idx])\n",
    "\n",
    "        # Assign B- and I- tags\n",
    "        entity_tokens = sorted(entity_tokens)\n",
    "        for i, token_idx in enumerate(entity_tokens):\n",
    "            if i == 0:\n",
    "                labels[token_idx] = f'B-{entity_label}'\n",
    "            else:\n",
    "                labels[token_idx] = f'I-{entity_label}'\n",
    "\n",
    "    return tokens, labels\n",
    "\n",
    "def create_ner_dataset(text_path, label_path, output_path):\n",
    "    \"\"\"\n",
    "    Create NER dataset in CSV format for training.\n",
    "    Format: id, tokens, ner_tags (space-separated)\n",
    "    \"\"\"\n",
    "    print(\"Loading data...\")\n",
    "    text_data, label_data = load_data(text_path, label_path)\n",
    "\n",
    "    print(\"Converting to token classification format...\")\n",
    "    processed_data = convert_to_token_classification(text_data, label_data)\n",
    "\n",
    "    print(f\"Found {len(processed_data)} reviews with NER annotations\")\n",
    "\n",
    "    # Create rows for CSV\n",
    "    rows = []\n",
    "    for item in processed_data:\n",
    "        tokens, labels = create_bio_tags(item['text'], item['entities'])\n",
    "\n",
    "        rows.append({\n",
    "            'id': item['id'],\n",
    "            'tokens': ' '.join(tokens),\n",
    "            'ner_tags': ' '.join(labels)\n",
    "        })\n",
    "\n",
    "    # Create DataFrame and save\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Dataset saved to {output_path}\")\n",
    "    print(f\"Total samples: {len(df)}\")\n",
    "\n",
    "    # Print statistics\n",
    "    print(\"\\n=== Dataset Statistics ===\")\n",
    "    all_tags = []\n",
    "    for tags in df['ner_tags']:\n",
    "        all_tags.extend(tags.split())\n",
    "\n",
    "    tag_counts = defaultdict(int)\n",
    "    for tag in all_tags:\n",
    "        tag_counts[tag] += 1\n",
    "\n",
    "    print(f\"Total tokens: {len(all_tags)}\")\n",
    "    print(\"\\nTag distribution:\")\n",
    "    for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / len(all_tags)) * 100\n",
    "        print(f\"  {tag}: {count} ({percentage:.2f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    TEXT_PATH = \"../../data/text_all_merged.json\"\n",
    "    LABEL_PATH = \"../../data/label_all_merged.json\"\n",
    "    OUTPUT_PATH = \"train_ner.csv\"\n",
    "\n",
    "    df = create_ner_dataset(TEXT_PATH, LABEL_PATH, OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a43517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
