{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d687f2",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04388efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers datasets seqeval scikit-learn pandas numpy protobuf sentencepiece accelerate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9d9c22",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c3dae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa71138",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed53845",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"train_ner.csv\"\n",
    "MODEL_NAME = \"xlm-roberta-large\"\n",
    "MAX_LENGTH = 256\n",
    "RANDOM_SEED = 42\n",
    "OUTPUT_DIR = \"xlm_roberta_ner_model\"\n",
    "SAVED_MODEL_DIR = \"../../model/NER/xlm_roberta_ner_saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d3848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2604d3",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65635ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1094\n",
      "Columns: ['id', 'tokens', 'ner_tags']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg_0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg_1</td>\n",
       "      <td>Robert DeNiro plays the most unbelievably inte...</td>\n",
       "      <td>B-ACTOR I-ACTOR O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg_2</td>\n",
       "      <td>I saw the capsule comment said \"great acting.\"...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg_3</td>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "      <td>O O O O O O O B-MOVIE I-MOVIE O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_4</td>\n",
       "      <td>This fanciful horror flick has Vincent Price p...</td>\n",
       "      <td>O O B-GENRE O O B-ACTOR I-ACTOR O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             tokens  \\\n",
       "0  neg_0  Story of a man who has unnatural feelings for ...   \n",
       "1  neg_1  Robert DeNiro plays the most unbelievably inte...   \n",
       "2  neg_2  I saw the capsule comment said \"great acting.\"...   \n",
       "3  neg_3  If I had not read Pat Barker's 'Union Street' ...   \n",
       "4  neg_4  This fanciful horror flick has Vincent Price p...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  B-ACTOR I-ACTOR O O O O O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O B-MOVIE I-MOVIE O O O O O O O O ...  \n",
       "4  O O B-GENRE O O B-ACTOR I-ACTOR O O O O O O O ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fd04997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 11\n",
      "Labels: ['B-ACTOR', 'B-CHARACTER', 'B-DIRECTOR', 'B-GENRE', 'B-MOVIE', 'I-ACTOR', 'I-CHARACTER', 'I-DIRECTOR', 'I-GENRE', 'I-MOVIE', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels from all tags\n",
    "all_tags = []\n",
    "for tags in df['ner_tags']:\n",
    "    all_tags.extend(tags.split())\n",
    "\n",
    "unique_labels = sorted(list(set(all_tags)))\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "452e4957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1094 samples\n",
      "\n",
      "Example:\n",
      "Tokens: ['Story', 'of', 'a', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'a']\n",
      "Tags: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Convert data to list format\n",
    "def prepare_data(df):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = row['tokens'].split()\n",
    "        tags = row['ner_tags'].split()\n",
    "        data.append({\n",
    "            'id': row['id'],\n",
    "            'tokens': tokens,\n",
    "            'ner_tags': [label2id[tag] for tag in tags]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "data = prepare_data(df)\n",
    "print(f\"Prepared {len(data)} samples\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"Tokens: {data[0]['tokens'][:10]}\")\n",
    "print(f\"Tags: {data[0]['ner_tags'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc46ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 929\n",
      "Val samples: 165\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Val samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57b779b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 929\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 165\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create HuggingFace datasets\n",
    "train_ds = Dataset.from_list(train_data)\n",
    "val_ds = Dataset.from_list(val_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd2b262",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63331312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: xlm-roberta-large\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "print(f\"Tokenizer loaded: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3324f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special tokens get -100 (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # First subword of a word gets the label\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # Subsequent subwords get -100 (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd08ed80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/929 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 929/929 [00:00<00:00, 1412.09 examples/s]\n",
      "Map: 100%|██████████| 165/165 [00:00<00:00, 1184.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 929\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 165\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_ds = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(encoded_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f6dbd4",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a7d4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: xlm-roberta-large\n",
      "Number of labels: 11\n",
      "Model parameters: 558,852,107\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {MODEL_NAME}\")\n",
    "print(f\"Number of labels: {len(unique_labels)}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bcb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb3770",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb75ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Convert to label names and filter out -100\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        true_label = []\n",
    "        true_prediction = []\n",
    "        for pred, lab in zip(prediction, label):\n",
    "            if lab != -100:  # Ignore special tokens\n",
    "                true_label.append(id2label[lab])\n",
    "                true_prediction.append(id2label[pred])\n",
    "        true_labels.append(true_label)\n",
    "        true_predictions.append(true_prediction)\n",
    "\n",
    "    # Calculate metrics using seqeval\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332628d",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9daf6cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99aded74",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb6e9034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33196/937411125.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='295' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [295/295 03:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.000100</td>\n",
       "      <td>0.067134</td>\n",
       "      <td>0.603829</td>\n",
       "      <td>0.618401</td>\n",
       "      <td>0.611028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.042150</td>\n",
       "      <td>0.744799</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.776012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.041371</td>\n",
       "      <td>0.760116</td>\n",
       "      <td>0.793363</td>\n",
       "      <td>0.776384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.036419</td>\n",
       "      <td>0.785924</td>\n",
       "      <td>0.808446</td>\n",
       "      <td>0.797026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.813762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=295, training_loss=0.1961568276760942, metrics={'train_runtime': 214.5372, 'train_samples_per_second': 21.651, 'train_steps_per_second': 1.375, 'total_flos': 2156987807009280.0, 'train_loss': 0.1961568276760942, 'epoch': 5.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded_ds[\"train\"],\n",
    "    eval_dataset=encoded_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79509faf",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42346f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluation on validation set =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/11 00:00 < 00:00, 13.78 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.0368\n",
      "eval_precision: 0.8071\n",
      "eval_recall: 0.8205\n",
      "eval_f1: 0.8138\n",
      "eval_runtime: 1.0122\n",
      "eval_samples_per_second: 163.0130\n",
      "eval_steps_per_second: 10.8680\n",
      "epoch: 5.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Evaluation on validation set =====\")\n",
    "val_metrics = trainer.evaluate(encoded_ds[\"validation\"])\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e559cd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Detailed Classification Report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ACTOR       0.92      0.86      0.89       250\n",
      "   CHARACTER       0.81      0.83      0.82       143\n",
      "    DIRECTOR       0.64      0.80      0.71        54\n",
      "       GENRE       0.37      0.40      0.38        35\n",
      "       MOVIE       0.81      0.85      0.83       181\n",
      "\n",
      "   micro avg       0.81      0.82      0.81       663\n",
      "   macro avg       0.71      0.75      0.73       663\n",
      "weighted avg       0.81      0.82      0.82       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report\n",
    "predictions, labels, _ = trainer.predict(encoded_ds[\"validation\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Convert to label names\n",
    "true_labels = []\n",
    "true_predictions = []\n",
    "\n",
    "for prediction, label in zip(predictions, labels):\n",
    "    true_label = []\n",
    "    true_prediction = []\n",
    "    for pred, lab in zip(prediction, label):\n",
    "        if lab != -100:\n",
    "            true_label.append(id2label[lab])\n",
    "            true_prediction.append(id2label[pred])\n",
    "    true_labels.append(true_label)\n",
    "    true_predictions.append(true_prediction)\n",
    "\n",
    "print(\"\\n===== Detailed Classification Report =====\")\n",
    "print(classification_report(true_labels, true_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb62a6",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e24c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../../model/NER/xlm_roberta_ner_saved\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained(SAVED_MODEL_DIR)\n",
    "tokenizer.save_pretrained(SAVED_MODEL_DIR)\n",
    "print(f\"Model saved to: {SAVED_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b41d73d",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384365cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Test Predictions =====\n",
      "\n",
      "Text: Christopher Nolan directed Inception starring Leonardo DiCaprio.\n",
      "Entities:\n",
      "  Christopher Nolan         -> DIRECTOR     (score: 0.971)\n",
      "  ception                   -> MOVIE        (score: 0.968)\n",
      "  Leonardo                  -> ACTOR        (score: 0.994)\n",
      "  Caprio                    -> ACTOR        (score: 0.937)\n",
      "\n",
      "Text: The Dark Knight is one of the best action movies ever made.\n",
      "Entities:\n",
      "  The Dark Knight           -> MOVIE        (score: 0.994)\n",
      "\n",
      "Text: Tom Hanks played the role of Forrest Gump brilliantly.\n",
      "Entities:\n",
      "  Tom Hanks                 -> ACTOR        (score: 0.979)\n",
      "  rest Gump                 -> CHARACTER    (score: 0.879)\n",
      "\n",
      "Text: Martin Scorsese's Goodfellas is a masterpiece of the crime genre.\n",
      "Entities:\n",
      "  Martin Scorse             -> DIRECTOR     (score: 0.973)\n",
      "  Goodfellas                -> MOVIE        (score: 0.994)\n",
      "  crime                     -> GENRE        (score: 0.684)\n",
      "\n",
      "Text: Quentin Tarantino's Pulp Fiction features John Travolta and Samuel L. Jackson.\n",
      "Entities:\n",
      "  Que                       -> DIRECTOR     (score: 0.966)\n",
      "  tin Tarantino             -> DIRECTOR     (score: 0.929)\n",
      "  Pulp Fiction              -> MOVIE        (score: 0.977)\n",
      "  John Travolta             -> ACTOR        (score: 0.979)\n",
      "  Samuel L                  -> ACTOR        (score: 0.987)\n",
      "  Jackson                   -> ACTOR        (score: 0.977)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model for inference\n",
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=SAVED_MODEL_DIR,\n",
    "    tokenizer=SAVED_MODEL_DIR,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "# Test examples\n",
    "test_texts = [\n",
    "    \"Christopher Nolan directed Inception starring Leonardo DiCaprio.\",\n",
    "    \"The Dark Knight is one of the best action movies ever made.\",\n",
    "    \"Tom Hanks played the role of Forrest Gump brilliantly.\",\n",
    "    \"Martin Scorsese's Goodfellas is a masterpiece of the crime genre.\",\n",
    "    \"Quentin Tarantino's Pulp Fiction features John Travolta and Samuel L. Jackson.\",\n",
    "]\n",
    "\n",
    "print(\"===== Test Predictions =====\")\n",
    "for text in test_texts:\n",
    "    print(f\"\\nText: {text}\")\n",
    "    results = ner_pipeline(text)\n",
    "    if results:\n",
    "        print(\"Entities:\")\n",
    "        for result in results:\n",
    "            print(f\"  {result['word']:25s} -> {result['entity_group']:12s} (score: {result['score']:.3f})\")\n",
    "    else:\n",
    "        print(\"  No entities detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12608b54",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a219145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos_601</td>\n",
       "      <td>I was surprised at the low rating this film go...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_602</td>\n",
       "      <td>I have never danced flamenco before, but someh...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_603</td>\n",
       "      <td>The music of Albeniz pervades this film. Once ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos_604</td>\n",
       "      <td>Saturday June 3, 6:30pm The Neptune Monday Jun...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos_605</td>\n",
       "      <td>If Saura hadn't done anything like this before...</td>\n",
       "      <td>O B-DIRECTOR O O O O O O B-MOVIE O O O O O O O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             tokens  \\\n",
       "0  pos_601  I was surprised at the low rating this film go...   \n",
       "1  pos_602  I have never danced flamenco before, but someh...   \n",
       "2  pos_603  The music of Albeniz pervades this film. Once ...   \n",
       "3  pos_604  Saturday June 3, 6:30pm The Neptune Monday Jun...   \n",
       "4  pos_605  If Saura hadn't done anything like this before...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "4  O B-DIRECTOR O O O O O O B-MOVIE O O O O O O O...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "TEST_DATA_PATH = \"test_ner.csv\"\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc511b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 45 test samples\n",
      "Dataset({\n",
      "    features: ['id', 'tokens', 'ner_tags'],\n",
      "    num_rows: 45\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data with the same function used for training\n",
    "test_data = prepare_data(test_df)\n",
    "print(f\"Prepared {len(test_data)} test samples\")\n",
    "\n",
    "# Create test dataset\n",
    "test_ds = Dataset.from_list(test_data)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b651442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 45/45 [00:00<00:00, 309.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 45\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and align labels for test data\n",
    "encoded_test_ds = test_ds.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names\n",
    ")\n",
    "\n",
    "print(encoded_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87e90400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluation on test set =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/3 00:00 < 00:00, 10.00 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.0365\n",
      "eval_precision: 0.8994\n",
      "eval_recall: 0.8385\n",
      "eval_f1: 0.8679\n",
      "eval_runtime: 0.4609\n",
      "eval_samples_per_second: 97.6450\n",
      "eval_steps_per_second: 6.5100\n",
      "epoch: 5.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"===== Evaluation on test set =====\")\n",
    "test_metrics = trainer.evaluate(encoded_test_ds)\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3392b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Detailed Classification Report (Test Set) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ACTOR       1.00      0.98      0.99        56\n",
      "   CHARACTER       0.84      0.73      0.78        37\n",
      "    DIRECTOR       0.75      1.00      0.86         9\n",
      "       GENRE       0.67      0.40      0.50        25\n",
      "       MOVIE       0.92      0.92      0.92        65\n",
      "\n",
      "   micro avg       0.90      0.84      0.87       192\n",
      "   macro avg       0.84      0.81      0.81       192\n",
      "weighted avg       0.89      0.84      0.86       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report for test set\n",
    "test_predictions, test_labels, _ = trainer.predict(encoded_test_ds)\n",
    "test_predictions = np.argmax(test_predictions, axis=2)\n",
    "\n",
    "# Convert to label names\n",
    "test_true_labels = []\n",
    "test_true_predictions = []\n",
    "\n",
    "for prediction, label in zip(test_predictions, test_labels):\n",
    "    true_label = []\n",
    "    true_prediction = []\n",
    "    for pred, lab in zip(prediction, label):\n",
    "        if lab != -100:\n",
    "            true_label.append(id2label[lab])\n",
    "            true_prediction.append(id2label[pred])\n",
    "    test_true_labels.append(true_label)\n",
    "    test_true_predictions.append(true_prediction)\n",
    "\n",
    "print(\"\\n===== Detailed Classification Report (Test Set) =====\")\n",
    "print(classification_report(test_true_labels, test_true_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
