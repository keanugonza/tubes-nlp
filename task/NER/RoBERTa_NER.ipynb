{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "084430b2",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba2ef25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers datasets seqeval scikit-learn pandas numpy protobuf sentencepiece accelerate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209eed9f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4f28c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification,\n",
    ")\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d61003",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9ff3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"train_ner.csv\"\n",
    "MODEL_NAME = \"roberta-large\"\n",
    "MAX_LENGTH = 256\n",
    "RANDOM_SEED = 42\n",
    "OUTPUT_DIR = \"roberta_ner_model\"\n",
    "SAVED_MODEL_DIR = \"../../model/NER/roberta_ner_saved\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f24b5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e80d5",
   "metadata": {},
   "source": [
    "# Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f75efa59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1094\n",
      "Columns: ['id', 'tokens', 'ner_tags']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg_0</td>\n",
       "      <td>Story of a man who has unnatural feelings for ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg_1</td>\n",
       "      <td>Robert DeNiro plays the most unbelievably inte...</td>\n",
       "      <td>B-ACTOR I-ACTOR O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg_2</td>\n",
       "      <td>I saw the capsule comment said \"great acting.\"...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg_3</td>\n",
       "      <td>If I had not read Pat Barker's 'Union Street' ...</td>\n",
       "      <td>O O O O O O O B-MOVIE I-MOVIE O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg_4</td>\n",
       "      <td>This fanciful horror flick has Vincent Price p...</td>\n",
       "      <td>O O B-GENRE O O B-ACTOR I-ACTOR O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                             tokens  \\\n",
       "0  neg_0  Story of a man who has unnatural feelings for ...   \n",
       "1  neg_1  Robert DeNiro plays the most unbelievably inte...   \n",
       "2  neg_2  I saw the capsule comment said \"great acting.\"...   \n",
       "3  neg_3  If I had not read Pat Barker's 'Union Street' ...   \n",
       "4  neg_4  This fanciful horror flick has Vincent Price p...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  B-ACTOR I-ACTOR O O O O O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O B-MOVIE I-MOVIE O O O O O O O O ...  \n",
       "4  O O B-GENRE O O B-ACTOR I-ACTOR O O O O O O O ...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "daa7cd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels: 11\n",
      "Labels: ['B-ACTOR', 'B-CHARACTER', 'B-DIRECTOR', 'B-GENRE', 'B-MOVIE', 'I-ACTOR', 'I-CHARACTER', 'I-DIRECTOR', 'I-GENRE', 'I-MOVIE', 'O']\n"
     ]
    }
   ],
   "source": [
    "# Extract unique labels from all tags\n",
    "all_tags = []\n",
    "for tags in df['ner_tags']:\n",
    "    all_tags.extend(tags.split())\n",
    "\n",
    "unique_labels = sorted(list(set(all_tags)))\n",
    "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(f\"Number of unique labels: {len(unique_labels)}\")\n",
    "print(f\"Labels: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01318490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1094 samples\n",
      "\n",
      "Example:\n",
      "Tokens: ['Story', 'of', 'a', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'a']\n",
      "Tags: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Convert data to list format\n",
    "def prepare_data(df):\n",
    "    data = []\n",
    "    for _, row in df.iterrows():\n",
    "        tokens = row['tokens'].split()\n",
    "        tags = row['ner_tags'].split()\n",
    "        data.append({\n",
    "            'id': row['id'],\n",
    "            'tokens': tokens,\n",
    "            'ner_tags': [label2id[tag] for tag in tags]\n",
    "        })\n",
    "    return data\n",
    "\n",
    "data = prepare_data(df)\n",
    "print(f\"Prepared {len(data)} samples\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"Tokens: {data[0]['tokens'][:10]}\")\n",
    "print(f\"Tags: {data[0]['ner_tags'][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2b694d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 929\n",
      "Val samples: 165\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and validation sets\n",
    "train_data, val_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.15,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_data)}\")\n",
    "print(f\"Val samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2aabd03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 929\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'ner_tags'],\n",
      "        num_rows: 165\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Create HuggingFace datasets\n",
    "train_ds = Dataset.from_list(train_data)\n",
    "val_ds = Dataset.from_list(val_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_ds,\n",
    "    \"validation\": val_ds,\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493987f",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b4c3dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded: roberta-large\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n",
    "print(f\"Tokenizer loaded: {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc50dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                # Special tokens get -100 (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                # First subword of a word gets the label\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                # Subsequent subwords get -100 (ignored in loss)\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c4ba800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/929 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 929/929 [00:00<00:00, 1074.15 examples/s]\n",
      "Map:   0%|          | 0/165 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 165/165 [00:00<00:00, 1144.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 929\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 165\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_ds = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(encoded_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb5628",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55e40b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded: roberta-large\n",
      "Number of labels: 11\n",
      "Model parameters: 354,321,419\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")\n",
    "\n",
    "print(f\"Model loaded: {MODEL_NAME}\")\n",
    "print(f\"Number of labels: {len(unique_labels)}\")\n",
    "print(f\"Model parameters: {model.num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "300dcb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed20a69",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd118cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Convert to label names and filter out -100\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for prediction, label in zip(predictions, labels):\n",
    "        true_label = []\n",
    "        true_prediction = []\n",
    "        for pred, lab in zip(prediction, label):\n",
    "            if lab != -100:  # Ignore special tokens\n",
    "                true_label.append(id2label[lab])\n",
    "                true_prediction.append(id2label[pred])\n",
    "        true_labels.append(true_label)\n",
    "        true_predictions.append(true_prediction)\n",
    "\n",
    "    # Calculate metrics using seqeval\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1 = f1_score(true_labels, true_predictions)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006ed4c",
   "metadata": {},
   "source": [
    "# Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "afa71fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=2,\n",
    "    report_to=\"none\",\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e2c42",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f17594b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34404/937411125.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='295' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [295/295 02:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.712700</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>0.710602</td>\n",
       "      <td>0.721980</td>\n",
       "      <td>0.716245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>0.823022</td>\n",
       "      <td>0.832606</td>\n",
       "      <td>0.827786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.028450</td>\n",
       "      <td>0.837681</td>\n",
       "      <td>0.841339</td>\n",
       "      <td>0.839506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.029545</td>\n",
       "      <td>0.853767</td>\n",
       "      <td>0.841339</td>\n",
       "      <td>0.847507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.029171</td>\n",
       "      <td>0.844118</td>\n",
       "      <td>0.835517</td>\n",
       "      <td>0.839795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=295, training_loss=0.13889382825059407, metrics={'train_runtime': 166.2283, 'train_samples_per_second': 27.943, 'train_steps_per_second': 1.775, 'total_flos': 2156987807009280.0, 'train_loss': 0.13889382825059407, 'epoch': 5.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=encoded_ds[\"train\"],\n",
    "    eval_dataset=encoded_ds[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fa0a5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38cbc6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluation on validation set =====\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/11 00:00 < 00:00, 14.18 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.0295\n",
      "eval_precision: 0.8538\n",
      "eval_recall: 0.8413\n",
      "eval_f1: 0.8475\n",
      "eval_runtime: 1.0132\n",
      "eval_samples_per_second: 162.8470\n",
      "eval_steps_per_second: 10.8560\n",
      "epoch: 5.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Evaluation on validation set =====\")\n",
    "val_metrics = trainer.evaluate(encoded_ds[\"validation\"])\n",
    "for k, v in val_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33e3dfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Detailed Classification Report =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ACTOR       0.91      0.90      0.91       259\n",
      "   CHARACTER       0.81      0.82      0.82       150\n",
      "    DIRECTOR       0.84      0.82      0.83        57\n",
      "       GENRE       0.44      0.42      0.43        36\n",
      "       MOVIE       0.88      0.86      0.87       185\n",
      "\n",
      "   micro avg       0.85      0.84      0.85       687\n",
      "   macro avg       0.78      0.77      0.77       687\n",
      "weighted avg       0.85      0.84      0.85       687\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ACTOR       0.91      0.90      0.91       259\n",
      "   CHARACTER       0.81      0.82      0.82       150\n",
      "    DIRECTOR       0.84      0.82      0.83        57\n",
      "       GENRE       0.44      0.42      0.43        36\n",
      "       MOVIE       0.88      0.86      0.87       185\n",
      "\n",
      "   micro avg       0.85      0.84      0.85       687\n",
      "   macro avg       0.78      0.77      0.77       687\n",
      "weighted avg       0.85      0.84      0.85       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report\n",
    "predictions, labels, _ = trainer.predict(encoded_ds[\"validation\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Convert to label names\n",
    "true_labels = []\n",
    "true_predictions = []\n",
    "\n",
    "for prediction, label in zip(predictions, labels):\n",
    "    true_label = []\n",
    "    true_prediction = []\n",
    "    for pred, lab in zip(prediction, label):\n",
    "        if lab != -100:\n",
    "            true_label.append(id2label[lab])\n",
    "            true_prediction.append(id2label[pred])\n",
    "    true_labels.append(true_label)\n",
    "    true_predictions.append(true_prediction)\n",
    "\n",
    "print(\"\\n===== Detailed Classification Report =====\")\n",
    "print(classification_report(true_labels, true_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadba26",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a4e1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../../model/NER/roberta_ner_saved\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained(SAVED_MODEL_DIR)\n",
    "tokenizer.save_pretrained(SAVED_MODEL_DIR)\n",
    "print(f\"Model saved to: {SAVED_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104ded0",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "819d357f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Test Predictions =====\n",
      "\n",
      "Text: Christopher Nolan directed Inception starring Leonardo DiCaprio.\n",
      "Entities:\n",
      "   Christopher Nolan   -> DIRECTOR     (score: 0.914)\n",
      "   Inception           -> MOVIE        (score: 0.992)\n",
      "   Leonardo DiCaprio   -> ACTOR        (score: 0.985)\n",
      "\n",
      "Text: The Dark Knight is one of the best action movies ever made.\n",
      "Entities:\n",
      "   The Dark Knight     -> MOVIE        (score: 0.975)\n",
      "\n",
      "Text: Tom Hanks played the role of Forrest Gump brilliantly.\n",
      "Entities:\n",
      "   Tom Hanks           -> ACTOR        (score: 0.982)\n",
      "   Forrest Gump        -> CHARACTER    (score: 0.918)\n",
      "\n",
      "Text: Martin Scorsese's Goodfellas is a masterpiece of the crime genre.\n",
      "Entities:\n",
      "   Martin Scorsese     -> DIRECTOR     (score: 0.973)\n",
      "   Goodfellas          -> MOVIE        (score: 0.995)\n",
      "   crime               -> GENRE        (score: 0.593)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model for inference\n",
    "from transformers import pipeline\n",
    "\n",
    "ner_pipeline = pipeline(\n",
    "    \"token-classification\",\n",
    "    model=SAVED_MODEL_DIR,\n",
    "    tokenizer=SAVED_MODEL_DIR,\n",
    "    aggregation_strategy=\"simple\"\n",
    ")\n",
    "\n",
    "# Test examples\n",
    "test_texts = [\n",
    "    \"Christopher Nolan directed Inception starring Leonardo DiCaprio.\",\n",
    "    \"The Dark Knight is one of the best action movies ever made.\",\n",
    "    \"Tom Hanks played the role of Forrest Gump brilliantly.\",\n",
    "    \"Martin Scorsese's Goodfellas is a masterpiece of the crime genre.\",\n",
    "]\n",
    "\n",
    "print(\"===== Test Predictions =====\")\n",
    "for text in test_texts:\n",
    "    print(f\"\\nText: {text}\")\n",
    "    results = ner_pipeline(text)\n",
    "    if results:\n",
    "        print(\"Entities:\")\n",
    "        for result in results:\n",
    "            print(f\"  {result['word']:20s} -> {result['entity_group']:12s} (score: {result['score']:.3f})\")\n",
    "    else:\n",
    "        print(\"  No entities detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecbfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b9ef3ff",
   "metadata": {},
   "source": [
    "# Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aecbd611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test samples: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos_601</td>\n",
       "      <td>I was surprised at the low rating this film go...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos_602</td>\n",
       "      <td>I have never danced flamenco before, but someh...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos_603</td>\n",
       "      <td>The music of Albeniz pervades this film. Once ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos_604</td>\n",
       "      <td>Saturday June 3, 6:30pm The Neptune Monday Jun...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pos_605</td>\n",
       "      <td>If Saura hadn't done anything like this before...</td>\n",
       "      <td>O B-DIRECTOR O O O O O O B-MOVIE O O O O O O O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             tokens  \\\n",
       "0  pos_601  I was surprised at the low rating this film go...   \n",
       "1  pos_602  I have never danced flamenco before, but someh...   \n",
       "2  pos_603  The music of Albeniz pervades this film. Once ...   \n",
       "3  pos_604  Saturday June 3, 6:30pm The Neptune Monday Jun...   \n",
       "4  pos_605  If Saura hadn't done anything like this before...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "1  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "2  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "3  O O O O O O O O O O O O O O O O O O O O O O O ...  \n",
       "4  O B-DIRECTOR O O O O O O B-MOVIE O O O O O O O...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load test data\n",
    "TEST_DATA_PATH = \"test_ner.csv\"\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5fb03909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 45 test samples\n",
      "Dataset({\n",
      "    features: ['id', 'tokens', 'ner_tags'],\n",
      "    num_rows: 45\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Prepare test data with the same function used for training\n",
    "test_data = prepare_data(test_df)\n",
    "print(f\"Prepared {len(test_data)} test samples\")\n",
    "\n",
    "# Create test dataset\n",
    "test_ds = Dataset.from_list(test_data)\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a08fd6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 45/45 [00:00<00:00, 402.66 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 45\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and align labels for test data\n",
    "encoded_test_ds = test_ds.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names\n",
    ")\n",
    "\n",
    "print(encoded_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a055bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Evaluation on test set =====\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_loss: 0.0364\n",
      "eval_precision: 0.8848\n",
      "eval_recall: 0.8284\n",
      "eval_f1: 0.8557\n",
      "eval_runtime: 0.2929\n",
      "eval_samples_per_second: 153.6170\n",
      "eval_steps_per_second: 10.2410\n",
      "epoch: 5.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"===== Evaluation on test set =====\")\n",
    "test_metrics = trainer.evaluate(encoded_test_ds)\n",
    "for k, v in test_metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9b77c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Detailed Classification Report (Test Set) =====\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ACTOR       0.98      1.00      0.99        61\n",
      "   CHARACTER       0.81      0.79      0.80        38\n",
      "    DIRECTOR       0.77      0.91      0.83        11\n",
      "       GENRE       0.64      0.33      0.44        27\n",
      "       MOVIE       0.91      0.88      0.89        67\n",
      "\n",
      "   micro avg       0.88      0.83      0.86       204\n",
      "   macro avg       0.82      0.78      0.79       204\n",
      "weighted avg       0.87      0.83      0.84       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get detailed classification report for test set\n",
    "test_predictions, test_labels, _ = trainer.predict(encoded_test_ds)\n",
    "test_predictions = np.argmax(test_predictions, axis=2)\n",
    "\n",
    "# Convert to label names\n",
    "test_true_labels = []\n",
    "test_true_predictions = []\n",
    "\n",
    "for prediction, label in zip(test_predictions, test_labels):\n",
    "    true_label = []\n",
    "    true_prediction = []\n",
    "    for pred, lab in zip(prediction, label):\n",
    "        if lab != -100:\n",
    "            true_label.append(id2label[lab])\n",
    "            true_prediction.append(id2label[pred])\n",
    "    test_true_labels.append(true_label)\n",
    "    test_true_predictions.append(true_prediction)\n",
    "\n",
    "print(\"\\n===== Detailed Classification Report (Test Set) =====\")\n",
    "print(classification_report(test_true_labels, test_true_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
